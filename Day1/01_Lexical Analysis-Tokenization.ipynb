{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"They told that their ages are 25 27 and 31 respectively\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the average of ages mentioned in the above sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['25', '27', '31']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ages = re.findall(r\"\\d+\",sent)\n",
    "\n",
    "ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ages = [int(age)for age in ages]\n",
    "len(ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.66666666666667"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg = 0 \n",
    "\n",
    "for age in ages:\n",
    "    avg = avg+int(age)/len(ages)\n",
    "\n",
    "avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.666666666666668"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([int(word) for word in sent.split() if word.isdigit()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"Hello friends ! How are you ? Welcome to Python Programming.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the functions \n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello friends !', 'How are you ?', 'Welcome to Python Programming.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Segmentation\n",
    "sent_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'friends',\n",
       " '!',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " '?',\n",
       " 'Welcome',\n",
       " 'to',\n",
       " 'Python',\n",
       " 'Programming',\n",
       " '.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the percentage of puncutation symbols present in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = word_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!', '?', '.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punc = [word for word in lst if not word.isalnum()]\n",
    "punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [word for word in lst]\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage = (len(punc)/len(a))*100\n",
    "\n",
    "percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.getsizeof('#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'मानस कुलकर्णी'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char =\"\\u092E\\u093E\\u0928\\u0938 \\u0915\\u0941\\u0932\\u0915\\u0930\\u094D\\u0923\\u0940\"\n",
    "char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['मानस', 'कुलकर्णी']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name.find(\"न\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [ 'योगेश', 'कुणाल', 'मानसी', 'मानस', 'आदित्य', 'पार्थ' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "मानसी\n",
      "मानस\n"
     ]
    }
   ],
   "source": [
    "for name in names:\n",
    "    if name.startswith('मा'):\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtext = '४८ कि. मी. अंतरावर आणि पुणे जिल्ह्यातील वेल्हे तालुक्यात व भोर गावाच्या वायव्येला २४ कि.मी. अंतरावर नीरा-वेळवंडी-कानंदी आणि गुंजवणी या नद्यांच्या खोऱ्यांच्या बेचक्यात मुरुंबदेवाचा डोंगर उभा आहे. मावळ भागामध्ये राज्यविस्तार साध्य करण्यासाठी राजगड आणि तोरणा हे दोन्ही किल्ले मोक्याच्या ठिकाणी होते. तोरणा Archived 2020-09-20 at the Wayback Machine. किल्ल्याचा बालेकिल्ला आकाराने लहान असल्यामुळे राजकीय केंद्र म्हणून हा किल्ला सोयीचा नव्हता. त्यामानाने राजगड दुर्गम असून त्याचा बालेकिल्ला बराच मोठा आहे. शिवाय राजगडाकडे कोणत्याही बाजूने येताना एखादी टेकडी किंवा नदी ओलांडावीच लागते. एवढी सुरक्षितता होती,म्हणून आपले राजकीय केंद्र म्हणून शिवाजी महाराजांनी Archived 2020-03-18 at the Wayback Machine. राजगडाची निवड केली. राजगडाला तीन माच्या व एक बालेकिल्ला आहे. राजगडचा बालेकिल्ला खूप उंच असून त्याची समुद्रसपाटीपासूनची उंची १३९४ मीटर आहे.' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'४८ कि. मी. अंतरावर आणि पुणे जिल्ह्यातील वेल्हे तालुक्यात व भोर गावाच्या वायव्येला २४ कि.मी. अंतरावर नीरा-वेळवंडी-कानंदी आणि गुंजवणी या नद्यांच्या खोऱ्यांच्या बेचक्यात मुरुंबदेवाचा डोंगर उभा आहे. मावळ भागामध्ये राज्यविस्तार साध्य करण्यासाठी राजगड आणि तोरणा हे दोन्ही किल्ले मोक्याच्या ठिकाणी होते. तोरणा Archived 2020-09-20 at the Wayback Machine. किल्ल्याचा बालेकिल्ला आकाराने लहान असल्यामुळे राजकीय केंद्र म्हणून हा किल्ला सोयीचा नव्हता. त्यामानाने राजगड दुर्गम असून त्याचा बालेकिल्ला बराच मोठा आहे. शिवाय राजगडाकडे कोणत्याही बाजूने येताना एखादी टेकडी किंवा नदी ओलांडावीच लागते. एवढी सुरक्षितता होती,म्हणून आपले राजकीय केंद्र म्हणून शिवाजी महाराजांनी Archived 2020-03-18 at the Wayback Machine. राजगडाची निवड केली. राजगडाला तीन माच्या व एक बालेकिल्ला आहे. राजगडचा बालेकिल्ला खूप उंच असून त्याची समुद्रसपाटीपासूनची उंची १३९४ मीटर आहे.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['४८',\n",
       " 'कि',\n",
       " '.',\n",
       " 'मी',\n",
       " '.',\n",
       " 'अंतरावर',\n",
       " 'आणि',\n",
       " 'पुणे',\n",
       " 'जिल्ह्यातील',\n",
       " 'वेल्हे',\n",
       " 'तालुक्यात',\n",
       " 'व',\n",
       " 'भोर',\n",
       " 'गावाच्या',\n",
       " 'वायव्येला',\n",
       " '२४',\n",
       " 'कि.मी',\n",
       " '.',\n",
       " 'अंतरावर',\n",
       " 'नीरा-वेळवंडी-कानंदी',\n",
       " 'आणि',\n",
       " 'गुंजवणी',\n",
       " 'या',\n",
       " 'नद्यांच्या',\n",
       " 'खोऱ्यांच्या',\n",
       " 'बेचक्यात',\n",
       " 'मुरुंबदेवाचा',\n",
       " 'डोंगर',\n",
       " 'उभा',\n",
       " 'आहे',\n",
       " '.',\n",
       " 'मावळ',\n",
       " 'भागामध्ये',\n",
       " 'राज्यविस्तार',\n",
       " 'साध्य',\n",
       " 'करण्यासाठी',\n",
       " 'राजगड',\n",
       " 'आणि',\n",
       " 'तोरणा',\n",
       " 'हे',\n",
       " 'दोन्ही',\n",
       " 'किल्ले',\n",
       " 'मोक्याच्या',\n",
       " 'ठिकाणी',\n",
       " 'होते',\n",
       " '.',\n",
       " 'तोरणा',\n",
       " 'Archived',\n",
       " '2020-09-20',\n",
       " 'at',\n",
       " 'the',\n",
       " 'Wayback',\n",
       " 'Machine',\n",
       " '.',\n",
       " 'किल्ल्याचा',\n",
       " 'बालेकिल्ला',\n",
       " 'आकाराने',\n",
       " 'लहान',\n",
       " 'असल्यामुळे',\n",
       " 'राजकीय',\n",
       " 'केंद्र',\n",
       " 'म्हणून',\n",
       " 'हा',\n",
       " 'किल्ला',\n",
       " 'सोयीचा',\n",
       " 'नव्हता',\n",
       " '.',\n",
       " 'त्यामानाने',\n",
       " 'राजगड',\n",
       " 'दुर्गम',\n",
       " 'असून',\n",
       " 'त्याचा',\n",
       " 'बालेकिल्ला',\n",
       " 'बराच',\n",
       " 'मोठा',\n",
       " 'आहे',\n",
       " '.',\n",
       " 'शिवाय',\n",
       " 'राजगडाकडे',\n",
       " 'कोणत्याही',\n",
       " 'बाजूने',\n",
       " 'येताना',\n",
       " 'एखादी',\n",
       " 'टेकडी',\n",
       " 'किंवा',\n",
       " 'नदी',\n",
       " 'ओलांडावीच',\n",
       " 'लागते',\n",
       " '.',\n",
       " 'एवढी',\n",
       " 'सुरक्षितता',\n",
       " 'होती',\n",
       " ',',\n",
       " 'म्हणून',\n",
       " 'आपले',\n",
       " 'राजकीय',\n",
       " 'केंद्र',\n",
       " 'म्हणून',\n",
       " 'शिवाजी',\n",
       " 'महाराजांनी',\n",
       " 'Archived',\n",
       " '2020-03-18',\n",
       " 'at',\n",
       " 'the',\n",
       " 'Wayback',\n",
       " 'Machine',\n",
       " '.',\n",
       " 'राजगडाची',\n",
       " 'निवड',\n",
       " 'केली',\n",
       " '.',\n",
       " 'राजगडाला',\n",
       " 'तीन',\n",
       " 'माच्या',\n",
       " 'व',\n",
       " 'एक',\n",
       " 'बालेकिल्ला',\n",
       " 'आहे',\n",
       " '.',\n",
       " 'राजगडचा',\n",
       " 'बालेकिल्ला',\n",
       " 'खूप',\n",
       " 'उंच',\n",
       " 'असून',\n",
       " 'त्याची',\n",
       " 'समुद्रसपाटीपासूनची',\n",
       " 'उंची',\n",
       " '१३९४',\n",
       " 'मीटर',\n",
       " 'आहे',\n",
       " '.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(mtext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Space Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Friends! How are you?\n",
      "Welcome to the world of Python Programming\n"
     ]
    }
   ],
   "source": [
    "text = open(r'C:\\Users\\Administrator.DAI-PC2\\Desktop\\NLP\\Day1\\test.txt','r')\n",
    "data = text.read()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Friends!',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you?\\nWelcome',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world',\n",
       " 'of',\n",
       " 'Python',\n",
       " 'Programming']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the class\n",
    "\n",
    "from nltk.tokenize import SpaceTokenizer\n",
    "\n",
    "# Create a object\n",
    "\n",
    "tk = SpaceTokenizer()\n",
    "\n",
    "# tokenize the data\n",
    "\n",
    "tk.tokenize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tab Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Friends!\tHow are you?\n",
      "Welcome to the world of \tPython Programming\n"
     ]
    }
   ],
   "source": [
    "text = open(r'C:\\Users\\Administrator.DAI-PC2\\Desktop\\NLP\\Day1\\test.txt','r')\n",
    "data = text.read()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello Friends!',\n",
       " 'How are you?\\nWelcome to the world of ',\n",
       " 'Python Programming']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the class\n",
    "\n",
    "from nltk.tokenize import TabTokenizer\n",
    "\n",
    "# Create a object\n",
    "\n",
    "tk = TabTokenizer()\n",
    "\n",
    "# tokenize the data\n",
    "\n",
    "tk.tokenize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Line Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello Friends!\\tHow are you?',\n",
       " 'Welcome to the world of \\tPython Programming']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the class\n",
    "\n",
    "from nltk.tokenize import LineTokenizer\n",
    "\n",
    "# Create a object\n",
    "\n",
    "tk = LineTokenizer()\n",
    "\n",
    "# tokenize the data\n",
    "\n",
    "tk.tokenize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Whitespace Tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Friends!',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you?',\n",
       " 'Welcome',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world',\n",
       " 'of',\n",
       " 'Python',\n",
       " 'Programming']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the class\n",
    "\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "# Create a object\n",
    "\n",
    "tk = WhitespaceTokenizer()\n",
    "\n",
    "# tokenize the data\n",
    "\n",
    "tk.tokenize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MWE Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = \"The Van Rossum is Python creator, visting Pune this week. The devlopmenrt comunity is very eager to meet Van Rossum.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Van Rossum is Python creator, visting Pune this week. The devlopmenrt comunity is very eager to meet Van Rossum.\n"
     ]
    }
   ],
   "source": [
    "print(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Van',\n",
       " 'Rossum',\n",
       " 'is',\n",
       " 'Python',\n",
       " 'creator',\n",
       " ',',\n",
       " 'visting',\n",
       " 'Pune',\n",
       " 'this',\n",
       " 'week',\n",
       " '.',\n",
       " 'The',\n",
       " 'devlopmenrt',\n",
       " 'comunity',\n",
       " 'is',\n",
       " 'very',\n",
       " 'eager',\n",
       " 'to',\n",
       " 'meet',\n",
       " 'Van',\n",
       " 'Rossum',\n",
       " '.']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Van Rossum',\n",
       " 'is',\n",
       " 'Python',\n",
       " 'creator',\n",
       " ',',\n",
       " 'visting',\n",
       " 'Pune',\n",
       " 'this',\n",
       " 'week',\n",
       " '.',\n",
       " 'The',\n",
       " 'devlopmenrt',\n",
       " 'comunity',\n",
       " 'is',\n",
       " 'very',\n",
       " 'eager',\n",
       " 'to',\n",
       " 'meet',\n",
       " 'Van Rossum',\n",
       " '.']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the class\n",
    "\n",
    "from nltk.tokenize import MWETokenizer\n",
    "\n",
    "# Create a object\n",
    "\n",
    "tk = MWETokenizer(separator=' ')\n",
    "\n",
    "# add Multi Word Expression\n",
    "\n",
    "tk.add_mwe(('Van','Rossum'))\n",
    "\n",
    "# tokenize the data\n",
    "\n",
    "tk.tokenize(word_tokenize(sent1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweet Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Friends!👏How are you?\n",
      "Welcome to the world of 👌Python Programming\n"
     ]
    }
   ],
   "source": [
    "text = open(r'C:\\Users\\Administrator.DAI-PC2\\Desktop\\NLP\\Day1\\test.txt','r')\n",
    "data = text.read()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Friends',\n",
       " '!',\n",
       " '👏',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " '?',\n",
       " 'Welcome',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world',\n",
       " 'of',\n",
       " '👌',\n",
       " 'Python',\n",
       " 'Programming']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the class\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "# Create a object\n",
    "\n",
    "tk = TweetTokenizer()\n",
    "\n",
    "# tokenize the data\n",
    "\n",
    "tk.tokenize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: \n",
      "This\n",
      "is\n",
      "some\n",
      "text\n",
      "with\n",
      "punctuation\n",
      ">\n",
      "Let's\n",
      "tokenize\n",
      "it\n",
      "Is\n",
      "it\n",
      "ok\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def custom_tokenizer(text):\n",
    "    return re.split(r\"[.,:?\\s]+\",text)\n",
    "\n",
    "text = \"This is some text with punctuation > Let's tokenize it. Is it ok?\"\n",
    "\n",
    "tokens = custom_tokenizer(text)\n",
    "\n",
    "print(\"Tokens: \")\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('student3.tsv')\n",
    "data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roll\tname\tclass\tmarks\tage\n",
      "1\tanil\tTE\t56.77\t22\n",
      "2\tamit\tTE\t59.77\t21\n",
      "3\taniket\tBE\t76.88\t19\n",
      "4\tajinkya\tTE\t69.66\t20\n",
      "5\tasha\tTE\t63.28\t20\n",
      "6\tayesha\tBE\t49.55\t20\n",
      "7\tamar\tBE\t65.34\t19\n",
      "8\tamita\tBE\t68.33\t23\n",
      "9\tamol\tTE\t56.75\t20\n",
      "10\tanmol\tBE\t78.66\t21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['roll\\tname\\tclass\\tmarks\\tage',\n",
       " '1\\tanil\\tTE\\t56.77\\t22',\n",
       " '2\\tamit\\tTE\\t59.77\\t21',\n",
       " '3\\taniket\\tBE\\t76.88\\t19',\n",
       " '4\\tajinkya\\tTE\\t69.66\\t20',\n",
       " '5\\tasha\\tTE\\t63.28\\t20',\n",
       " '6\\tayesha\\tBE\\t49.55\\t20',\n",
       " '7\\tamar\\tBE\\t65.34\\t19',\n",
       " '8\\tamita\\tBE\\t68.33\\t23',\n",
       " '9\\tamol\\tTE\\t56.75\\t20',\n",
       " '10\\tanmol\\tBE\\t78.66\\t21',\n",
       " '']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.split('\\n')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list =[]\n",
    "\n",
    "for data in data:\n",
    "    row = data.split('\\t')\n",
    "    data_list.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['roll', 'name', 'class', 'marks', 'age'],\n",
       " ['1', 'anil', 'TE', '56.77', '22'],\n",
       " ['2', 'amit', 'TE', '59.77', '21'],\n",
       " ['3', 'aniket', 'BE', '76.88', '19'],\n",
       " ['4', 'ajinkya', 'TE', '69.66', '20'],\n",
       " ['5', 'asha', 'TE', '63.28', '20'],\n",
       " ['6', 'ayesha', 'BE', '49.55', '20'],\n",
       " ['7', 'amar', 'BE', '65.34', '19'],\n",
       " ['8', 'amita', 'BE', '68.33', '23'],\n",
       " ['9', 'amol', 'TE', '56.75', '20'],\n",
       " ['10', 'anmol', 'BE', '78.66', '21'],\n",
       " ['']]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = data_list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', 'anil', 'TE', '56.77', '22'],\n",
       " ['2', 'amit', 'TE', '59.77', '21'],\n",
       " ['3', 'aniket', 'BE', '76.88', '19'],\n",
       " ['4', 'ajinkya', 'TE', '69.66', '20'],\n",
       " ['5', 'asha', 'TE', '63.28', '20'],\n",
       " ['6', 'ayesha', 'BE', '49.55', '20'],\n",
       " ['7', 'amar', 'BE', '65.34', '19'],\n",
       " ['8', 'amita', 'BE', '68.33', '23'],\n",
       " ['9', 'amol', 'TE', '56.75', '20'],\n",
       " ['10', 'anmol', 'BE', '78.66', '21']]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DNN_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
